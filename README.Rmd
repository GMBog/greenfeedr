---
output: github_document
---
<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/",
  out.width = "100%"
)
```

# greenfeedr <img src="man/figures/GFSticker.png" align="right" width="15.2%"/>

<!-- badges: start -->
[![R-CMD-check](https://github.com/GMBog/greenfeedr/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/GMBog/greenfeedr/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

## Overview

greenfeedr provides a set of functions that help you work with GreenFeed data:

* `get_gfdata()` downloads GreenFeed data via API.
* `report_gfdata()` downloads and generates markdown reports of daily and final GreenFeed data.
* `process_gfdata()` processes and averages daily or final GreenFeed data.
* `pellin()` processes pellet intakes from GreenFeed units.
* `viseat()` processes GreenFeed visits.

Most of these use the same daily and final data from GreenFeed system.

## Citation

More complete information about how to use greenfeedr can be found in: ...

## Cheat Sheet

<a href="https://github.com/GMBog/greenfeedr/raw/main/man/figures/Cheatsheet.pdf"><img src="https://github.com/GMBog/greenfeedr/raw/main/man/figures/Cheatsheet.png" width="480" height="360"/></a>

## Installation

You can install the development version of greenfeedr from [GitHub](https://github.com/GMBog/greenfeedr) with:

```{r, eval = FALSE}
# install.packages("pak")
pak::pak("GMBog/greenfeedr")
```

## Usage

```{r libraries, include = FALSE, message = FALSE}
library(dplyr)
library(purrr)
library(readxl)
```

Here we present an example of how to use `process_gfdata()`:

```{r setup, message = FALSE}
library(greenfeedr)
```

Note that we received the finalized data (or Summarized Data) for our study using GreenFeed from C-Lock Inc. So, now we need to process all the daily records obtained.

The data looks like:

```{r data, echo = FALSE, message = FALSE}
finaldata <- readxl::read_excel(system.file("extdata", "StudyName_FinalReport.xlsx", package = "greenfeedr"))
head(finaldata, n = 5)
```

The first step is to investigate the total number of records, records per day, and days with records per week we have in our GreenFeed data. 

To do this we will use the `process_gfdata()` function and test 3 threshold values that will define the records we will retain for further analysis. Note that the function includes 3 parameters:
- **`param1`**: The number of records per day. 
 - This parameter controls the minimum number of records that must be present for each day in the dataset to be considered valid.
- **`param2`**: The number of days with records per week. 
 - This parameter ensures that a minimum number of days within a week have valid records to be included in the analysis.
- **`min_time`**: The minimum duration of a record. 
 - This parameter specifies the minimum time threshold for each record to be considered valid.

We can make an iterative process evaluating all possible combinations of parameters. Then, we define the parameters as follows:

```{r parameters}
# Define the parameter space for param1 (i), param2 (j), and min_time (k):
i <- seq(1, 3)
j <- seq(3, 7)
k <- seq(2, 5)

# Generate all combinations of i, j, and k
param_combinations <- expand.grid(param1 = i, param2 = j, min_time = k)
```

Interestingly, we have `r nrow(param_combinations)` combinations of our 3 parameters (param1, param2, and min_time).

The next step, is to evaluate the function `process_gfdata()` with the defined set of parameters. Note that the function can handle as argument a file path to the data files or the data as data frame.

```{r Example}
# Helper function to call process_gfdata and extract relevant information
process_and_summarize <- function(param1, param2, min_time) {
  data <- process_gfdata(
    data = finaldata,
    start_date = "2024-05-13",
    end_date = "2024-05-25",
    param1 = param1,
    param2 = param2,
    min_time = min_time
  )

  # Extract daily_data and weekly_data
  daily_data <- data$daily_data
  weekly_data <- data$weekly_data

  # Calculate the required metrics
  records_d <- nrow(daily_data)
  cows_d <- length(unique(daily_data$RFID))

  mean_dCH4 <- mean(daily_data$CH4GramsPerDay, na.rm = TRUE)
  sd_dCH4 <- sd(daily_data$CH4GramsPerDay, na.rm = TRUE)
  CV_dCH4 <- sd(daily_data$CH4GramsPerDay, na.rm = TRUE) / mean(daily_data$CH4GramsPerDay, na.rm = TRUE)
  mean_dCO2 <- mean(daily_data$CO2GramsPerDay, na.rm = TRUE)
  sd_dCO2 <- sd(daily_data$CO2GramsPerDay, na.rm = TRUE)
  CV_dCO2 <- sd(daily_data$CO2GramsPerDay, na.rm = TRUE) / mean(daily_data$CO2GramsPerDay, na.rm = TRUE)

  records_w <- nrow(weekly_data)
  cows_w <- length(unique(weekly_data$RFID))

  mean_wCH4 <- mean(weekly_data$CH4GramsPerDay, na.rm = TRUE)
  sd_wCH4 <- sd(weekly_data$CH4GramsPerDay, na.rm = TRUE)
  CV_wCH4 <- sd(weekly_data$CH4GramsPerDay, na.rm = TRUE) / mean(weekly_data$CH4GramsPerDay, na.rm = TRUE)
  mean_wCO2 <- mean(weekly_data$CO2GramsPerDay, na.rm = TRUE)
  sd_wCO2 <- sd(weekly_data$CO2GramsPerDay, na.rm = TRUE)
  CV_wCO2 <- sd(weekly_data$CO2GramsPerDay, na.rm = TRUE) / mean(weekly_data$CO2GramsPerDay, na.rm = TRUE)

  # Return a summary row
  return(data.frame(
    param1 = param1,
    param2 = param2,
    min_time = min_time,
    records_d = records_d,
    cows_d = cows_d,
    mean_dCH4 = round(mean_dCH4, 1),
    sd_dCH4 = round(sd_dCH4, 1),
    CV_dCH4 = round(CV_dCH4, 2),
    mean_dCO2 = round(mean_dCO2, 1),
    sd_dCO2 = round(sd_dCO2, 1),
    CV_dCO2 = round(CV_dCO2, 2),
    records_w = records_w,
    cows_w = cows_w,
    mean_wCH4 = round(mean_wCH4, 1),
    sd_wCH4 = round(sd_wCH4, 1),
    CV_wCH4 = round(CV_wCH4, 2),
    mean_wCO2 = round(mean_wCO2, 1),
    sd_wCO2 = round(sd_wCO2, 1),
    CV_wCO2 = round(CV_wCO2, 2)
  ))
}
```

```{r Results, include = FALSE}
# Apply helper function to all combinations and combine results into a data frame
data <- param_combinations %>%
  purrr::pmap_dfr(process_and_summarize)
```

Finally, the results from our function will be placed in a data frame with the following structure:

```{r Results table, message = FALSE}
head(data)
```

Also, it is possible to compute Pearson correlations between the different parameters and number of records, and/or the gas production average.

```{r Correaltions, echo = FALSE}
cat("Daily data:")
round(cor(data[, c("param1", "param2", "min_time", "records_d", "cows_d", "mean_dCH4", "CV_dCH4")],
  use = "complete.obs"
), 2)

cat(" ")
cat("Weekly data:")
round(cor(data[, c("param1", "param2", "min_time", "records_w", "cows_w", "mean_wCH4", "CV_wCH4")],
  use = "complete.obs"
), 2)
```

That gives the user an idea of what are the pros and cons of being more or less conservative when processing GreenFeed data for analysis. In general, the more conservative the parameters are, the fewer records are retained in the data.

## Getting help

If you encounter a clear bug, please file an issue with a minimal reproducible example on [GitHub](https://github.com/GMBog/greenfeedr).
