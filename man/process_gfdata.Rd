% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/process_gfdata.R
\name{process_gfdata}
\alias{process_gfdata}
\title{Process Daily and Final GreenFeed Data}
\arguments{
\item{file}{File with GreenFeed data}

\item{start_date}{Start date of the study}

\item{end_date}{End date of the study}

\item{input_type}{Input data could be from daily or final report: daily or final}

\item{param1}{Number of records per day to be consider for analysis}

\item{param2}{Number of days with records per week to be consider for analysis}

\item{min_time}{Minimum number of minutes for a records to be consider for analysis. By default min_time is 2}
}
\value{
Two data sets with daily and weekly processed GreenFeed data
}
\description{
`process_gfdata()` processes and computes daily and weekly averages
    for daily and final GreenFeed data, organizing it into structured datasets.
    This function handles data cleaning, aggregation, and summarization to facilitate
    further analysis and reporting.
}
\examples{
file1 <- system.file("extdata", "StudyName_GFdata.csv", package = "greenfeedr")
data1 <- process_gfdata(file1,
  input_type = "daily",
  start_date = "2024-05-13",
  end_date = "2024-05-25",
  param1 = 2,
  param2 = 3
)
head(data1)

file2 <- system.file("extdata", "StudyName_FinalReport.xlsx", package = "greenfeedr")
data2 <- process_gfdata(file2,
  input_type = "final",
  start_date = "2024-05-13",
  end_date = "2024-05-25",
  param1 = 2,
  param2 = 3
)

head(data2)

}
