% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/process_gfdata.R
\name{process_gfdata}
\alias{process_gfdata}
\title{Process Daily and Final GreenFeed Data}
\arguments{
\item{file}{File with GreenFeed data in daily or final format}

\item{Start_Date}{Start date of the study}

\item{End_Date}{End date of the study}

\item{input_type}{Input data could be from daily or final report: "daily" or "final"}

\item{param1}{Number of records per day to be consider for analysis}

\item{param2}{Number of days with records per week to be consider for analysis}

\item{min_time}{Minimum number of minutes for a records to be consider for analysis}
}
\value{
Datasets with GreenFeed processed data in a daily and weekly format
}
\description{
`process_gfdata()` processes and computes daily and weekly averages
    for daily and final GreenFeed data, organizing it into structured datasets.
    This function handles data cleaning, aggregation, and summarization to facilitate
    further analysis and reporting.
}
\examples{
file1 <- system.file("extdata", "StudyName_GFdata.csv", package = "greenfeedr")
data1 <- process_gfdata(file1,
                       Start_Date = "2024-05-13",
                       input_type = "daily",
                       param1 = 2,
                       param2 = 3,
                       min_time = 2)
head(data1)

file2 <- system.file("extdata", "StudyName_FinalReport.xlsx", package = "greenfeedr")
data2 <- process_gfdata(file2,
                       Start_Date = "2024-05-13",
                       End_Date = "2024-05-25",
                       input_type = "final",
                       param1 = 2,
                       param2 = 3,
                       min_time = 2)

head(data2)

}
